"""
Onglet Mise √† Jour
Gestion de la mise √† jour des donn√©es et d√©tection des changements
"""

import streamlit as st
import pandas as pd
from typing import Dict
from datetime import datetime
import time

# Import du composant d'affichage des fichiers (optionnel)
try:
    from ui.components.file_detection_display import render_detected_files_section
    FILE_DISPLAY_AVAILABLE = True
except ImportError:
    FILE_DISPLAY_AVAILABLE = False


def render(managers: Dict):
    """
    Affiche l'onglet Mise √† Jour
    
    Args:
        managers: Dictionnaire contenant tous les managers
                 - 'data': DataManager
                 - 'change': ChangeDetector
                 - 'history': HistoryManager
                 - 'watchlist': WatchlistManager
                 - 'risk': RiskAnalyzer
                 - 'alert': AlertSystem
    """
    from backend.logger import get_logger
    logger = get_logger()
    
    st.header("Mise √† Jour des Donn√©es")
    
    st.info("Cette section permet de charger les nouvelles donn√©es et de d√©tecter les changements.")
    
    # Afficher les fichiers sources d√©tect√©s (si le composant est disponible)
    if FILE_DISPLAY_AVAILABLE:
        render_detected_files_section(managers['data'], expanded=False)
        st.divider()
    
    if st.button("Charger et Agr√©ger les Donn√©es", type="primary"):
        logger.info("=" * 80)
        logger.info("D√âBUT DU PROCESSUS DE CHARGEMENT ET AGR√âGATION")
        logger.info("=" * 80)

        with st.spinner("Chargement des donn√©es en cours..."):
            try:
                logger.info("√âTAPE 1: Chargement de l'ancien fichier agr√©g√©")
                old_aggregated = managers['data'].load_aggregated_data()
                logger.info(f"‚úì Ancien fichier agr√©g√© charg√©: {len(old_aggregated)} enregistrements")
                if not old_aggregated.empty:
                    logger.info(f"  - Colonnes: {list(old_aggregated.columns)[:5]}... ({len(old_aggregated.columns)} total)")
                    if 'unique_substance_id' in old_aggregated.columns:
                        duplicates = old_aggregated['unique_substance_id'].duplicated().sum()
                        logger.info(f"  - Doublons d√©tect√©s: {duplicates}")
                    else:
                        logger.warning("  - unique_substance_id manquant dans l'ancien fichier")

                logger.info("√âTAPE 2: Chargement des nouvelles listes depuis les fichiers sources")
                # IMPORTANT: Charger AVANT l'archivage et garder en m√©moire
                new_lists = managers['data'].load_all_lists()
                logger.info(f"‚úì Nouvelles listes charg√©es et gard√©es en m√©moire: {list(new_lists.keys())}")
                for list_name, df in new_lists.items():
                    logger.info(f"  - {list_name}: {len(df)} enregistrements, colonnes: {list(df.columns)[:3]}...")

                logger.info("√âTAPE 3: Agr√©gation des nouvelles donn√©es")
                # Passer les listes d√©j√† charg√©es pour √©viter de recharger les fichiers
                aggregated_df = managers['data'].aggregate_all_data(preloaded_lists=new_lists)
                logger.info(f"‚úì Nouvelles donn√©es agr√©g√©es: {len(aggregated_df)} enregistrements")

                logger.info("√âTAPE 4: Sauvegarde du fichier agr√©g√©")
                was_saved = managers['data'].save_aggregated_data(aggregated_df)
                logger.info(f"‚úì R√©sultat de la sauvegarde: was_saved={was_saved}")

                # Invalider le cache pour forcer le rechargement des donn√©es dans les autres onglets
                st.cache_data.clear()
                logger.info("‚úì Cache invalid√© pour forcer le rechargement des donn√©es")

                # ARCHIVAGE ET SUPPRESSION APR√àS LA SAUVEGARDE ET LE CHARGEMENT
                logger.info("√âTAPE 5: Archivage et suppression des fichiers sources")
                logger.info("  (Les donn√©es sont d√©j√† en m√©moire, on peut supprimer les fichiers)")
                try:
                    archived_count = managers['data'].archive_source_files()
                    if archived_count > 0:
                        st.info(f"üì¶ {archived_count} fichiers archiv√©s dans data/archives/ et supprim√©s de data/input/")
                        logger.info(f"‚úì Archivage et nettoyage r√©ussi: {archived_count} fichiers")
                    else:
                        st.info("‚ÑπÔ∏è Aucun fichier √† archiver (d√©j√† archiv√©s lors d'une ex√©cution pr√©c√©dente)")
                        logger.info("  - Aucun fichier √† archiver (d√©j√† fait)")
                except FileNotFoundError as e:
                    # Fichiers d√©j√† archiv√©s/supprim√©s - ce n'est pas une erreur critique
                    logger.info(f"  - Fichiers d√©j√† archiv√©s: {str(e)}")
                    st.info("‚ÑπÔ∏è Fichiers sources d√©j√† archiv√©s lors d'une ex√©cution pr√©c√©dente")
                except Exception as e:
                    # Erreur non critique, on continue le processus
                    logger.warning(f"‚ö† Avertissement lors de l'archivage (non bloquante): {str(e)}")
                    st.warning(f"‚ö†Ô∏è Avertissement lors de l'archivage: {str(e)}")

                # Cr√©er des placeholders pour les messages temporaires
                message_placeholder1 = st.empty()
                message_placeholder2 = st.empty()

                if was_saved:
                    message_placeholder1.success(f"Donn√©es agr√©g√©es et sauvegard√©es avec succ√®s! {len(aggregated_df)} enregistrements charg√©s.")
                else:
                    message_placeholder1.info(f"Donn√©es agr√©g√©es ({len(aggregated_df)} enregistrements). Aucun changement d√©tect√©, fichier non modifi√©.")

                # La d√©tection des changements utilise les donn√©es D√âJ√Ä EN M√âMOIRE
                # On ne recharge PAS les fichiers (ils ont √©t√© supprim√©s)
                with st.spinner("D√©tection des changements..."):
                    logger.info("√âTAPE 6: D√©tection des changements")
                    logger.info("  (Utilisation des donn√©es d√©j√† charg√©es en m√©moire)")
                    
                    # Pr√©parer le dictionnaire des anciennes listes. Il sera vide lors du premier chargement.
                    old_lists = {}
                    if not old_aggregated.empty:
                        # V√©rifier que les colonnes n√©cessaires existent
                        if 'cas_id' not in old_aggregated.columns or 'cas_name' not in old_aggregated.columns:
                            logger.error(f"‚úó Colonnes manquantes dans old_aggregated. Colonnes pr√©sentes: {list(old_aggregated.columns)}")
                            st.error("Erreur: Le fichier agr√©g√© ne contient pas les colonnes attendues (cas_id, cas_name). Veuillez v√©rifier la configuration.")
                        else:
                            for list_name in old_aggregated['source_list'].unique():
                                old_lists[list_name] = old_aggregated[old_aggregated['source_list'] == list_name].copy()
                            logger.info(f"  - Anciennes listes pr√©par√©es: {list(old_lists.keys())}")
                    else:
                        logger.info("  - Aucune ancienne liste (premier chargement)")
                    
                    logger.info("√âTAPE 7: Comparaison des anciennes et nouvelles listes")
                    logger.info(f"  - Anciennes listes: {len(old_lists)}")
                    logger.info(f"  - Nouvelles listes: {len(new_lists)}")
                    changes_df = managers['change'].detect_all_changes(old_lists, new_lists)
                    logger.info(f"‚úì Changements d√©tect√©s: {len(changes_df)} enregistrements")

                    # Cr√©er le tableau r√©capitulatif par liste source
                    st.subheader("üìã R√©capitulatif des Changements par Liste")

                    summary_data = []
                    all_list_names = set(old_lists.keys()) | set(new_lists.keys())
                    logger.info(f"  - Traitement de {len(all_list_names)} listes pour le r√©capitulatif")
                    for list_name in all_list_names:
                        list_changes = changes_df[changes_df['source_list'] == list_name] if not changes_df.empty else pd.DataFrame()
                        insertions = len(list_changes[list_changes['change_type'] == 'insertion']) if not list_changes.empty else 0
                        modifications = len(list_changes[list_changes['change_type'] == 'modification']) if not list_changes.empty else 0
                        deletions = len(list_changes[list_changes['change_type'] == 'deletion']) if not list_changes.empty else 0
                        
                        status = '‚ö™ Pas de changement'
                        if insertions > 0 or modifications > 0 or deletions > 0:
                            status = '‚úÖ Changements d√©tect√©s'

                        summary_data.append({
                            'Liste Source': list_name,
                            'Insertions': insertions,
                            'Modifications': modifications,
                            'Suppressions': deletions,
                            'Statut': status
                        })
                        
                        logger.info(f"    ‚Ä¢ {list_name}: +{insertions} ~{modifications} -{deletions}")

                    summary_df = pd.DataFrame(summary_data)
                    
                    # Sauvegarder le r√©sum√© actuel dans l'historique
                    managers['history'].save_summary(summary_df)
                    logger.info("‚úì R√©sum√© sauvegard√© dans l'historique")
                    
                    # Charger et afficher l'historique complet des r√©sum√©s
                    summary_history_df = managers['history'].load_summary_history()
                    st.dataframe(summary_history_df, use_container_width=True, hide_index=True)

                    # Afficher les m√©triques de r√©sum√©
                    st.subheader("üìä R√©sum√© de la Mise √† Jour")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    total_substances = len(aggregated_df)
                    insertions = len(changes_df[changes_df['change_type'] == 'insertion']) if not changes_df.empty else 0
                    deletions = len(changes_df[changes_df['change_type'] == 'deletion']) if not changes_df.empty else 0
                    modifications = len(changes_df[changes_df['change_type'] == 'modification']) if not changes_df.empty else 0
                    
                    # Corriger le nombre d'insertions pour le premier chargement
                    if old_aggregated.empty and total_substances > 0:
                        insertions = total_substances

                    col1.metric("Substances Trait√©es", total_substances)
                    col2.metric("‚úÖ Insertions", insertions)
                    col3.metric("‚ùå Suppressions", deletions)
                    col4.metric("‚úèÔ∏è Modifications", modifications)

                    if not changes_df.empty:
                        logger.info("√âTAPE 8: Sauvegarde des changements dans l'historique")
                        managers['history'].save_changes(changes_df)
                        logger.info(f"‚úì Historique mis √† jour avec {len(changes_df)} changements")

                        # Cr√©er les alertes pour les substances watchlist√©es
                        logger.info("√âTAPE 9: Cr√©ation des alertes")
                        managers['alert'].create_alerts_from_changes(
                            changes_df,
                            managers['watchlist'],
                            managers['risk'],
                            aggregated_df,
                            managers['history'].load_history()
                        )
                        logger.info("‚úì Alertes cr√©√©es avec succ√®s")

                        message_placeholder2.success(f"{len(changes_df)} changements d√©tect√©s et enregistr√©s!")

                        st.subheader("Aper√ßu des Changements")
                        st.dataframe(changes_df.head(10), use_container_width=True)
                    else:
                        logger.info("  - Aucun changement d√©tect√©")
                        message_placeholder2.info("Aucun changement d√©tect√©.")

                logger.info("=" * 80)
                logger.info("‚úì‚úì‚úì FIN DU PROCESSUS DE CHARGEMENT ET AGR√âGATION - SUCC√àS ‚úì‚úì‚úì")
                logger.info("=" * 80)

                # Afficher un bouton de rafra√Æchissement
                st.divider()
                st.success("‚úÖ Mise √† jour termin√©e avec succ√®s! Les donn√©es sont maintenant visibles dans l'onglet 'Donn√©es Agr√©g√©es'.")
                
                if st.button("üîÑ Rafra√Æchir l'Application", type="primary", use_container_width=True):
                    st.rerun()

                # Faire dispara√Ætre les messages apr√®s 5 secondes
                time.sleep(5)
                message_placeholder1.empty()
                message_placeholder2.empty()

            except Exception as e:
                logger.error("=" * 80)
                logger.error("‚úó‚úó‚úó FIN DU PROCESSUS DE CHARGEMENT ET AGR√âGATION - ERREUR ‚úó‚úó‚úó")
                logger.error(f"Exception: {str(e)}")
                logger.error("=" * 80)
                logger.exception("Traceback complet:")
                st.error(f"Erreur lors de la mise √† jour: {str(e)}")
                st.exception(e)