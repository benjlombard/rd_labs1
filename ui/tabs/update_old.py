"""
Onglet Mise √† Jour
Gestion de la mise √† jour des donn√©es et d√©tection des changements
"""

import streamlit as st
import pandas as pd
from typing import Dict
from datetime import datetime
import time


def render(managers: Dict):
    """
    Affiche l'onglet Mise √† Jour
    
    Args:
        managers: Dictionnaire contenant tous les managers
                 - 'data': DataManager
                 - 'change': ChangeDetector
                 - 'history': HistoryManager
                 - 'watchlist': WatchlistManager
                 - 'risk': RiskAnalyzer
                 - 'alert': AlertSystem
    """
    from backend.logger import get_logger
    logger = get_logger()
    
    st.header("Mise √† Jour des Donn√©es")
    
    st.info("Cette section permet de charger les nouvelles donn√©es et de d√©tecter les changements.")
    
    if st.button("Charger et Agr√©ger les Donn√©es", type="primary"):
        logger.info("=" * 80)
        logger.info("D√âBUT DU PROCESSUS DE CHARGEMENT ET AGR√âGATION")
        logger.info("=" * 80)

        with st.spinner("Archivage des fichiers sources..."):
            try:
                logger.info("√âTAPE 1: Archivage des fichiers sources")
                # Archiver les fichiers sources avant le chargement
                archived_count = managers['data'].archive_source_files()
                if archived_count > 0:
                    st.info(f"üì¶ {archived_count} fichiers archiv√©s dans data/archives/")
                    logger.info(f"Archivage r√©ussi: {archived_count} fichiers archiv√©s")
                else:
                    logger.info("Aucun fichier √† archiver")

            except Exception as e:
                logger.error(f"Erreur lors de l'archivage: {str(e)}", exc_info=True)
                st.warning(f"Avertissement lors de l'archivage: {str(e)}")

        with st.spinner("Chargement des donn√©es en cours..."):
            try:
                logger.info("√âTAPE 2: Chargement de l'ancien fichier agr√©g√©")
                old_aggregated = managers['data'].load_aggregated_data()
                logger.info(f"Ancien fichier agr√©g√© charg√©: {len(old_aggregated)} enregistrements")
                if not old_aggregated.empty:
                    logger.info(f"Colonnes: {list(old_aggregated.columns)}")
                    if 'unique_substance_id' in old_aggregated.columns:
                        duplicates = old_aggregated['unique_substance_id'].duplicated().sum()
                        logger.info(f"Doublons d√©tect√©s dans l'ancien fichier (via unique_substance_id): {duplicates}")
                    else:
                        logger.warning("unique_substance_id manquant dans l'ancien fichier")

                logger.info("√âTAPE 3: Agr√©gation des nouvelles donn√©es")
                aggregated_df = managers['data'].aggregate_all_data()
                logger.info(f"Nouvelles donn√©es agr√©g√©es: {len(aggregated_df)} enregistrements")

                logger.info("√âTAPE 4: Sauvegarde du fichier agr√©g√©")
                was_saved = managers['data'].save_aggregated_data(aggregated_df)
                logger.info(f"R√©sultat de la sauvegarde: was_saved={was_saved}")

                # Cr√©er des placeholders pour les messages temporaires
                message_placeholder1 = st.empty()
                message_placeholder2 = st.empty()

                if was_saved:
                    message_placeholder1.success(f"Donn√©es agr√©g√©es et sauvegard√©es avec succ√®s! {len(aggregated_df)} enregistrements charg√©s.")
                else:
                    message_placeholder1.info(f"Donn√©es agr√©g√©es ({len(aggregated_df)} enregistrements). Aucun changement d√©tect√©, fichier non modifi√©.")

                # La d√©tection des changements est maintenant ex√©cut√©e de mani√®re inconditionnelle.
                # Lors du premier chargement, old_aggregated est vide, et le ChangeDetector
                # classifiera correctement tous les enregistrements comme des insertions.
                with st.spinner("D√©tection des changements..."):
                    logger.info("√âTAPE 5: D√©tection des changements")
                    
                    # Charger les nouvelles listes √† partir des fichiers sources
                    new_lists = managers['data'].load_all_lists()
                    logger.info(f"Nouvelles listes charg√©es: {list(new_lists.keys())}")

                    # Pr√©parer le dictionnaire des anciennes listes. Il sera vide lors du premier chargement.
                    old_lists = {}
                    if not old_aggregated.empty:
                        # V√©rifier que les colonnes n√©cessaires existent
                        if 'cas_id' not in old_aggregated.columns or 'cas_name' not in old_aggregated.columns:
                            logger.error(f"Colonnes manquantes dans old_aggregated. Colonnes pr√©sentes: {list(old_aggregated.columns)}")
                            st.error("Erreur: Le fichier agr√©g√© ne contient pas les colonnes attendues (cas_id, cas_name). Veuillez v√©rifier la configuration.")
                        else:
                            for list_name in old_aggregated['source_list'].unique():
                                old_lists[list_name] = old_aggregated[old_aggregated['source_list'] == list_name].copy()
                    
                    logger.info("√âTAPE 6: D√©tection des changements pour toutes les listes")
                    changes_df = managers['change'].detect_all_changes(old_lists, new_lists)
                    logger.info(f"Changements d√©tect√©s: {len(changes_df)} enregistrements")

                    # Cr√©er le tableau r√©capitulatif par liste source
                    st.subheader("üìã R√©capitulatif des Changements par Liste")

                    summary_data = []
                    all_list_names = set(old_lists.keys()) | set(new_lists.keys())
                    for list_name in all_list_names:
                        list_changes = changes_df[changes_df['source_list'] == list_name] if not changes_df.empty else pd.DataFrame()
                        insertions = len(list_changes[list_changes['change_type'] == 'insertion']) if not list_changes.empty else 0
                        modifications = len(list_changes[list_changes['change_type'] == 'modification']) if not list_changes.empty else 0
                        deletions = len(list_changes[list_changes['change_type'] == 'deletion']) if not list_changes.empty else 0
                        
                        status = '‚ö™ Pas de changement'
                        if insertions > 0 or modifications > 0 or deletions > 0:
                            status = '‚úÖ Changements d√©tect√©s'

                        summary_data.append({
                            'Liste Source': list_name,
                            'Insertions': insertions,
                            'Modifications': modifications,
                            'Suppressions': deletions,
                            'Statut': status
                        })

                    summary_df = pd.DataFrame(summary_data)
                    
                    # Sauvegarder le r√©sum√© actuel dans l'historique
                    managers['history'].save_summary(summary_df)
                    
                    # Charger et afficher l'historique complet des r√©sum√©s
                    summary_history_df = managers['history'].load_summary_history()
                    st.dataframe(summary_history_df, use_container_width=True, hide_index=True)

                    # Afficher les m√©triques de r√©sum√©
                    st.subheader("üìä R√©sum√© de la Mise √† Jour")
                    col1, col2, col3, col4 = st.columns(4)
                    
                    total_substances = len(aggregated_df)
                    insertions = len(changes_df[changes_df['change_type'] == 'insertion']) if not changes_df.empty else 0
                    deletions = len(changes_df[changes_df['change_type'] == 'deletion']) if not changes_df.empty else 0
                    modifications = len(changes_df[changes_df['change_type'] == 'modification']) if not changes_df.empty else 0
                    
                    # Corriger le nombre d'insertions pour le premier chargement
                    if old_aggregated.empty and total_substances > 0:
                        insertions = total_substances

                    col1.metric("Substances Trait√©es", total_substances)
                    col2.metric("‚úÖ Insertions", insertions)
                    col3.metric("‚ùå Suppressions", deletions)
                    col4.metric("‚úèÔ∏è Modifications", modifications)

                    if not changes_df.empty:
                        logger.info("√âTAPE 7: Sauvegarde des changements dans l'historique")
                        managers['history'].save_changes(changes_df)
                        logger.info(f"Historique mis √† jour avec {len(changes_df)} changements")

                        # Cr√©er les alertes pour les substances watchlist√©es
                        logger.info("√âTAPE 8: Cr√©ation des alertes")
                        managers['alert'].create_alerts_from_changes(
                            changes_df,
                            managers['watchlist'],
                            managers['risk'],
                            aggregated_df,
                            managers['history'].load_history()
                        )
                        logger.info("Alertes cr√©√©es avec succ√®s")

                        message_placeholder2.success(f"{len(changes_df)} changements d√©tect√©s et enregistr√©s!")

                        st.subheader("Aper√ßu des Changements")
                        st.dataframe(changes_df.head(10), use_container_width=True)
                    else:
                        logger.info("Aucun changement d√©tect√©")
                        message_placeholder2.info("Aucun changement d√©tect√©.")

                logger.info("=" * 80)
                logger.info("FIN DU PROCESSUS DE CHARGEMENT ET AGR√âGATION - SUCC√àS")
                logger.info("=" * 80)

                # Faire dispara√Ætre les messages apr√®s 5 secondes
                time.sleep(5)
                message_placeholder1.empty()
                message_placeholder2.empty()

            except Exception as e:
                logger.error("=" * 80)
                logger.error("FIN DU PROCESSUS DE CHARGEMENT ET AGR√âGATION - ERREUR")
                logger.error(f"Exception: {str(e)}")
                logger.error("=" * 80)
                logger.exception("Traceback complet:")
                st.error(f"Erreur lors de la mise √† jour: {str(e)}")
                st.exception(e)